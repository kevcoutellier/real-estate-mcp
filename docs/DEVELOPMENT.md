# Guide de D√©veloppement - MCP Real Estate

## üèóÔ∏è Architecture

### Structure du Code Principal

```
src/
‚îú‚îÄ‚îÄ main.py                 # MCP principal avec analyses int√©gr√©es
‚îú‚îÄ‚îÄ rental_analyzer.py      # Logique d'investissement locatif
‚îú‚îÄ‚îÄ dealer_analyzer.py      # Logique marchand de biens
‚îî‚îÄ‚îÄ scrapers/              # Modules de scraping par site
```

### Classes Principales

#### `EnrichedRealEstateMCP`
- **H√©rite de** : `RealEstateMCP`
- **Fonctionnalit√©s** : Recherche + enrichissement g√©ographique + analyses d'investissement
- **M√©thodes cl√©s** :
  - `search_properties()` : Recherche multi-sources
  - `analyze_investment_opportunity()` : Analyse d'opportunit√©s
  - `compare_investment_strategies()` : Comparaison de strat√©gies

#### `RentalMarketAnalyzer`
- **Responsabilit√©** : Analyses d'investissement locatif
- **Donn√©es** : Base de loyers, fiscalit√©, rendements
- **M√©thodes** : `analyze_rental_investment()`, `estimate_rental_income()`

#### `PropertyDealerAnalyzer`
- **Responsabilit√©** : Analyses marchand de biens
- **Donn√©es** : Co√ªts r√©novation, marges, timing
- **M√©thodes** : `analyze_dealer_opportunity()`, `estimate_renovation_costs()`

## üîß Ajout de Nouvelles Fonctionnalit√©s

### 1. Nouveau Scraper

```python
# Dans src/scrapers/nouveau_site.py
class NouveauSiteScraper(BaseScraper):
    def __init__(self):
        super().__init__("nouveau_site")
    
    async def search_properties(self, params: SearchParams) -> List[PropertyListing]:
        # Impl√©mentation du scraping
        pass
```

### 2. Nouvelle M√©trique d'Investissement

```python
# Dans rental_analyzer.py ou dealer_analyzer.py
def calculate_nouvelle_metrique(self, listing: PropertyListing) -> float:
    """Calcule une nouvelle m√©trique d'investissement"""
    # Logique de calcul
    return metrique_value
```

### 3. Nouveau Profil d'Investissement

```python
# Dans main.py
class InvestmentProfile(Enum):
    RENTAL_INVESTOR = "rental_investor"
    PROPERTY_DEALER = "property_dealer"
    NOUVEAU_PROFIL = "nouveau_profil"  # Ajouter ici
    BOTH = "both"
```

## üß™ Tests et Validation

### Tests Unitaires
```bash
# Tests des analyseurs
python -m pytest tests/test_analyzers.py

# Tests d'int√©gration
python examples/test_integrated_mcp.py
```

### Tests de Performance
```python
# Mesurer les temps de r√©ponse
import time
start = time.time()
results = await mcp.analyze_investment_opportunity(...)
print(f"Temps d'ex√©cution: {time.time() - start:.2f}s")
```

## üìä Donn√©es et Configuration

### Base de Donn√©es Locative
```python
# Structure dans main.py
rental_database = {
    "ville": {
        "studio": {"min": 400, "max": 600, "avg": 500},
        "T2": {"min": 600, "max": 900, "avg": 750},
        # ...
    }
}
```

### Co√ªts de R√©novation
```python
# Structure dans main.py
renovation_costs = {
    "peinture": {"min": 15, "max": 25, "unit": "m¬≤"},
    "electricite": {"min": 80, "max": 120, "unit": "m¬≤"},
    # ...
}
```

## üîç Debugging et Logs

### Configuration des Logs
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
```

### Points de Debug Importants
- Recherche de propri√©t√©s : v√©rifier les param√®tres de recherche
- Analyses d'investissement : valider les calculs financiers
- Scraping : surveiller les erreurs SSL et timeouts

### Scripts de Diagnostic
```bash
# Diagnostic complet
python scripts/diagnostic_mcp.py

# Test de connectivit√©
python scripts/test_scrapers.py
```

## üöÄ D√©ploiement

### Variables d'Environnement
```bash
# .env
REAL_ESTATE_API_KEY=your_api_key
LOG_LEVEL=INFO
SCRAPING_DELAY=1
```

### Configuration MCP
```json
{
  "mcpServers": {
    "real-estate": {
      "command": "python",
      "args": ["mcp_server.py"],
      "cwd": "/path/to/real-estate-MCP"
    }
  }
}
```

## üîÑ Maintenance

### Mise √† Jour des Donn√©es
- **Loyers** : Mettre √† jour `rental_database` trimestriellement
- **Co√ªts r√©novation** : R√©viser `renovation_costs` annuellement
- **Scrapers** : Surveiller les changements de sites web

### Monitoring
- Surveiller les logs pour les erreurs de scraping
- V√©rifier les temps de r√©ponse des analyses
- Contr√¥ler la qualit√© des donn√©es retourn√©es

## üìà Optimisations

### Performance
- Mise en cache des r√©sultats de recherche
- Parall√©lisation des analyses d'investissement
- Optimisation des requ√™tes de scraping

### Qualit√© des Donn√©es
- Validation des prix et surfaces
- Filtrage des doublons
- Enrichissement automatique manquant

## ü§ù Contribution

### Standards de Code
- PEP 8 pour le style Python
- Type hints obligatoires
- Docstrings pour toutes les m√©thodes publiques
- Tests unitaires pour les nouvelles fonctionnalit√©s

### Workflow Git
1. Cr√©er une branche feature/nom-fonctionnalit√©
2. D√©velopper avec tests
3. Valider avec les exemples
4. Pull request avec description d√©taill√©e

---

**Derni√®re mise √† jour** : Janvier 2025
